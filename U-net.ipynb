{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow import keras\n",
    "from keras_unet_collection import models, losses\n",
    "from google.colab import drive\n",
    "from skimage import color\n",
    "import pydicom as dicom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keras_unet_collection\n",
    "!pip install pydicom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip '/content/drive/My Drive/data-v2/iaaa-data-v3.zip' -d '/content/drive/My Drive/data-v2/data-v2-unzip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH = 512\n",
    "IMG_HEIGHT = 256\n",
    "IMG_CHANNELS = 1\n",
    "\n",
    "DATA_PATH = '/content/drive/My Drive/data-v2/data-v2-unzip/iaaa-data-v3/DICOM/' # images\n",
    "Mask_path1= '/content/drive/My Drive/data-v2/data-v2-unzip/iaaa-data-v3/masks/'   # masks\n",
    "\n",
    "\n",
    "seed = 42\n",
    "random.seed = seed\n",
    "np.random.seed = seed\n",
    " \n",
    "image_ids = next(os.walk(DATA_PATH))[2]\n",
    "mask_ids= next(os.walk(Mask_path1))[2]\n",
    "# img = imread(DATA_PATH+ image_ids[1])[:,:]\n",
    "# imshow(img)\n",
    "# plt.show()\n",
    "X = np.zeros((len(image_ids), IMG_HEIGHT, IMG_WIDTH))\n",
    "\n",
    "Y = np.zeros((len(image_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool_)\n",
    "\n",
    "padding_ = np.zeros((IMG_HEIGHT,IMG_WIDTH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(image_ids))\n",
    "x=image_ids.index('2.25.305861492438344748144578306421271906759.dcm')\n",
    "# x = np.where(image_ids == '2.25.228745877808304447814199720807861699408.dcm')\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, id_ in tqdm(enumerate(image_ids), total=len(image_ids)):\n",
    "  try:\n",
    "    path = DATA_PATH \n",
    "    img = dicom.dcmread(DATA_PATH+ id_)\n",
    "    img = img.pixel_array[:,:]\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    image = img.copy()\n",
    "\n",
    "    image[:25,:] = padding_[:25,:]\n",
    "    image[img.shape[0]-25:img.shape[0],:] = padding_[img.shape[0]-25:img.shape[0],:]\n",
    "\n",
    "    image[:,:50] = padding_[:,:50]\n",
    "    image[:,img.shape[1]-80:img.shape[1]] = padding_[:,img.shape[1]-80:img.shape[1]]\n",
    "    X[n] = image\n",
    "    mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool_)\n",
    "    \n",
    "    for mask_file in next(os.walk(Mask_path1))[2]:\n",
    "      # print(mask_file[:len(mask_file) - 3])\n",
    "      # print(id_[:len(id_) - 3])\n",
    "      if mask_file[:len(mask_file) - 3]==id_[:len(id_) - 3]:\n",
    "        mask_ = imread(Mask_path1 + mask_file)\n",
    "        mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant',\n",
    "                                      preserve_range=True), axis=-1)\n",
    "        mask = np.maximum(mask, mask_)\n",
    "        mask[:50,:50] = 0    \n",
    "    Y[n] = mask\n",
    "  except:\n",
    "    print('error')\n",
    "    \n",
    "x_train=X \n",
    "y_train=Y\n",
    "\n",
    "print('Done!')\n",
    "\n",
    "image_x = random.randint(0, len(image_ids)-1)\n",
    "imshow(x_train[image_x],cmap='gray')\n",
    "plt.show()\n",
    "imshow(np.squeeze(y_train[image_x]),cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "s = tf.keras.layers.Lambda(lambda x: x / 255)(inputs)\n",
    "\n",
    "# Encoding\n",
    "c1 = tf.keras.layers.Conv2D(16, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(s)\n",
    "c1 = tf.keras.layers.Dropout(0.1)(c1)\n",
    "c1 = tf.keras.layers.Conv2D(16, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
    "p1 = tf.keras.layers.MaxPooling2D((2,2))(c1)\n",
    "\n",
    "c2 = tf.keras.layers.Conv2D(32, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
    "c2 = tf.keras.layers.Dropout(0.1)(c2)\n",
    "c2 = tf.keras.layers.Conv2D(32, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
    "p2 = tf.keras.layers.MaxPooling2D((2,2))(c2)\n",
    "\n",
    "c3 = tf.keras.layers.Conv2D(64, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
    "c3 = tf.keras.layers.Dropout(0.2)(c3)\n",
    "c3 = tf.keras.layers.Conv2D(64, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
    "p3 = tf.keras.layers.MaxPooling2D((2,2))(c3)\n",
    "\n",
    "c4 = tf.keras.layers.Conv2D(128, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
    "c4 = tf.keras.layers.Dropout(0.2)(c4)\n",
    "c4 = tf.keras.layers.Conv2D(128, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
    "p4 = tf.keras.layers.MaxPooling2D((2,2))(c4)\n",
    "\n",
    "c5 = tf.keras.layers.Conv2D(256, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
    "c5 = tf.keras.layers.Dropout(0.3)(c5)\n",
    "c5 = tf.keras.layers.Conv2D(256, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
    "\n",
    "#Decoding\n",
    "u6 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "u6 = tf.keras.layers.concatenate([u6, c4])\n",
    "c6 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
    "c6 = tf.keras.layers.Dropout(0.2)(c6)\n",
    "c6 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
    "\n",
    "u7 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "u7 = tf.keras.layers.concatenate([u7, c3])\n",
    "c7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
    "c7 = tf.keras.layers.Dropout(0.2)(c7)\n",
    "c7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
    " \n",
    "u8 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
    "u8 = tf.keras.layers.concatenate([u8, c2])\n",
    "c8 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
    "c8 = tf.keras.layers.Dropout(0.1)(c8)\n",
    "c8 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
    " \n",
    "u9 = tf.keras.layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
    "u9 = tf.keras.layers.concatenate([u9, c1], axis=3)\n",
    "c9 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
    "c9 = tf.keras.layers.Dropout(0.1)(c9)\n",
    "c9 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n",
    "\n",
    "outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
    " \n",
    "model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', losses.dice_coef])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = tf.keras.callbacks.ModelCheckpoint('/content/model_3rdm.h5', verbose=1, save_best_only=True)\n",
    "callbacks= [\n",
    "            tf.keras.callbacks.EarlyStopping(patience=5, monitor='val_loss'),\n",
    "            tf.keras.callbacks.TensorBoard(log_dir='./logs')]\n",
    "results = model.fit(x_train,y_train, validation_split=0.1, batch_size=16, epochs=30, callbacks=callbacks)\n",
    "t = time.time()\n",
    "my_keras_model_filepath = '/content/drive/My Drive/my models/saved_model_577_diffszie_512x256.h5'.format(int(t))\n",
    "print(my_keras_model_filepath)\n",
    "model.save(my_keras_model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_v1 = keras.models.load_model('/content/drive/My Drive/my models/saved_model_577_diffszie_512x256.h5', compile=False)\n",
    "model_v1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', losses.dice_coef])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loss=results.history['loss']\n",
    "training_accuracy=results.history['accuracy']\n",
    "validation_loss=results.history['val_loss']\n",
    "validation_accuracy=results.history['val_accuracy']\n",
    "\n",
    "epochs_range=range(len(training_accuracy))\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, training_accuracy, label='Training Accuracy')\n",
    "plt.plot(epochs_range, validation_accuracy, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, training_loss, label='Training Loss')\n",
    "plt.plot(epochs_range, validation_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_PATH = '/content/drive/My Drive/Colab Notebooks/test/'\n",
    "\n",
    "test_ids = next(os.walk(TEST_PATH))[2]\n",
    "\n",
    "len(test_ids)\n",
    "X_test = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH))\n",
    "\n",
    "sizes_test=[]\n",
    "print('resizing training images')\n",
    "for n, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):\n",
    "  path = TEST_PATH \n",
    "  img = dicom.dcmread(path+ id_)\n",
    "  img = img.pixel_array[:,:]\n",
    "  sizes_test.append([img.shape[0],img.shape[1]])\n",
    "  img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "  X_test[n]=img "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test = model_v1.predict(X_test, verbose=1)\n",
    "preds_test_t = (preds_test > 0.5).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = random.randint(0, len(preds_test_t))\n",
    "imshow(X_test[1],cmap='gray')\n",
    "plt.show()\n",
    "imshow(np.squeeze(preds_test_t[1]),cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "  imshow(np.squeeze(y_train[i]),cmap='gray')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_v1\n",
    "image_x = random.randint(46, len(image_ids)-1)\n",
    "imshow(x_train[image_x],cmap='gray')\n",
    "plt.show()\n",
    "imshow(np.squeeze(y_train[image_x]),cmap='gray')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
